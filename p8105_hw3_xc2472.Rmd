---
title: "HW 3"
author: "Xing Chen"
date: 2019-10-12
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(ggridges)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.wideth = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


# Problem 1

**import the dataset instacart**

```{r}
data("instacart")

instacart %>% 
  group_by(department) %>% 
  summarize(n = n())

instacart %>% 
  group_by(department) %>% 
  summarize(
    mean_order_hour = mean(order_hour_of_day, na.rm = TRUE)
  )
```

**Description**

There are `r nrow(instacart)` observations in the instacart dataset. Each row represents a
product from an order. There are 21 types of department in this dataset and the mean order
hour of the day is for each department is around 13. The `aisle` variable represents the 
type of the goods that are ordered and `order_day shows` the day of the week on which the 
order is placed. For example, the first row in the dataset tells us yogurt was ordered on 
Thursday and this product has been ordered by this person in the past. 


```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(items = n()) %>% 
  arrange(desc(items))
```

There are `r nrow(instacart %>% group_by(aisle) %>% summarize(items = n()))` aisles exist and the most ordered item is fresh vegetables. 

**Create a plot**

```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(items = n()) %>% 
  filter(items > 10000) %>% 
  ggplot(aes(x = items, y = aisle)) + 
  geom_point() +
  labs(
    title = "number of items ordered in each aisle",
    x = "the number of items",
    y = "type of aisles",
    caption = "number of aisles larger than 10000 "
  )
```

From the graph, fresh vegetables and fresh fruits are ordered much more than other items. 
The ordered numbers of packaged vegetables fruits and yogurt also stand out. 

**Create a table**

```{r}
instacart %>% 
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) %>% 
  group_by(aisle, product_name) %>% 
  summarize(order_number = n()) %>% 
  arrange(desc(order_number)) %>% 
  filter(min_rank(desc(order_number)) < 4) %>% 
  knitr::kable()
```

In packaged vegetables fruits aisle, organic baby spinach, organic raspberries, and 
organic blueberries are the 3 most ordered items with order number 9784, 5546, and 4966 
respectively. 
In baking ingredients aisle, light brown sugar, pure baking soda, and cane sugar are the 3
most ordered items with order number 499, 387, and 336 respectively. 
In dog food care aisle, snack sticks chicken & rice recipe dog treats, organix chicken & 
brown rice recipe, and small dog biscuits are the 3 most ordered items, with order number 
30, 28, 26 respectively. 

**Create a table**

```{r}
instacart %>% 
  group_by(product_name, order_dow) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  summarize(
    mean_order_time = mean(order_hour_of_day, na.rm = TRUE)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_order_time
  ) %>% 
  knitr::kable(digits = 2)
```

For coffee ice cream, the mean order hour of a day for each day of the week is 13.77, 
14.32, 15.38, 15.32, 15.22, 12.26, 13.83. 
For pink lady apples, the mean order hour of a day for each day of the week is 13.44, 
11.36, 11.70, 14.25, 11.55, 12.78, 11.94.


# problem 2

## Data import and data cleaning

```{r}
data("brfss_smart2010")

brfss_data = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(
    topic == "Overall Health", 
    response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")
  ) %>% 
  mutate(
    response = factor(response),
    response = fct_relevel(response, "Poor", "Fair", "Good", "Very good", "Excellent")
  )
```

**Q1**

```{r}
brfss_data %>% 
  filter(
    year %in% c(2002, 2010)
  ) %>% 
  group_by(year, locationabbr) %>% 
  summarize(
    unique_location = n_distinct(locationdesc)
  ) %>% 
  filter(unique_location > 6) %>% 
knitr::kable()
```

In 2002, there are 6 states were observed at 7 or more places. 
In 2010, there are 14 states were observed at 7 or more places. 

**Q2**

```{r}
brfss_excellent = 
  brfss_data %>% 
  filter(response == "Excellent") %>% 
  group_by(locationabbr, year) %>% 
  mutate(
    data_value_average = mean(data_value, na.rm = TRUE)) %>% 
  select(year, locationabbr, data_value_average) %>% 
  distinct()

brfss_excellent %>% 
  ggplot(aes(x = year, y = data_value_average, color = locationabbr)) +
  geom_line() +
  viridis::scale_color_viridis(
    name = "State", 
    discrete = TRUE
  ) +
  labs(
    title = "Spaghetti plot",
    y = "the average data value"
  ) +
  theme(legend.position = "right")
```

The spaghetti plot is hard to read but a general decreasing trend can be found when the 
year goes up. 

**Q3**

```{r}
brfss_data %>% 
  filter(year %in% c(2006, 2010), locationabbr == "NY") %>% 
  ggplot(aes(x = locationdesc, y = data_value, fill = response)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(~year) +
  coord_flip() +
  labs(
    title = "Ridges plot",
    x = "data values"
  )
```

For the counties observed both in year 2006 and 2010. The distribution of each responses 
doesn't change much. That is the percentage for each response doesn't change 
significantly. 


# Problem 3

## load and clean the data

```{r}
accel_data = 
  read_csv(file = "./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day_type = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday"),
    day = forcats::fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
  ) %>% 
  select(week, day_id, day, day_type, everything()) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_prefix = "activity_",
    names_to = "activity",
    values_to = "count_minutes"
  )
```

There are `r nrow(accel_data)` rows and `r ncol(accel_data)` variables in this dataset.
This resulting dataset is in long format, transformed from a wide format.


## Create a table showing the total activity minutes in each day

```{r}
accel_tidy_data = 
  accel_data %>% 
  group_by(day_id) %>% 
  mutate(
    total_activity = sum(count_minutes))

accel_tidy_data %>% 
  pivot_wider(
    names_from = "activity",
    values_from = "count_minutes"
  ) %>% 
  select(day_id, day, total_activity) %>% 
  knitr::kable()
```

Generally, the total activity were very high on Friday except one, eventhough, it may not 
be the highest. The total activity for Wednesday is relatively stable comepared to other 
days. As a whole, there is no particular trend can be found. 


## Create a sing panel plot to show the 24-hour activity time courses

```{r}
accel_tidy_data %>% 
  ggplot(aes(x = activity, y = count_minutes, group = day_id, color = day)) +
  geom_line() 
```

Across the 35 days observation, the count_minutes fluctuate in a big range and it is hard 
to see some detailed trends. But in overall, the Wednesday's count_minute is lower than 
other days in a week in general and Wednesday is also generally more stable than other 
days. 


